{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae4b1a6b",
   "metadata": {},
   "source": [
    "# Classifier - Using YOLO + VLM outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19c12ab",
   "metadata": {},
   "source": [
    "## Install required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad0188d-e175-4b89-8040-b83031bccf5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19afe0bb",
   "metadata": {},
   "source": [
    "## Prepare BERT tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f86fbb-598c-46d0-af95-03425483750d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased', output_hidden_states=True)\n",
    "model.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ef0267",
   "metadata": {},
   "source": [
    "## Read and tokenize VLM outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0785ac87-9685-4cae-ae49-317d21f91bf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "INPUT_JSON = \"outputs/combined_rgb/llava_test_prompt2.json\"\n",
    "INPUT_ADDITION_JSON = \"outputs/combined_rgb/llava_test_prompt2_addition.json\"\n",
    "OUTPUT_JSON = \"outputs/combined_rgb/llava_test_vectorized.json\"\n",
    "\n",
    "with open(INPUT_JSON, \"r\") as f1:\n",
    "    data = json.load(f1)\n",
    "\n",
    "    outputs = data[\"outputs\"]\n",
    "\n",
    "with open(INPUT_ADDITION_JSON) as f2:\n",
    "    data_addition = json.load(f2)\n",
    "\n",
    "    outputs_addition = data_addition[\"outputs\"]\n",
    "\n",
    "print(len(outputs))\n",
    "print(len(outputs_addition))\n",
    "outputs = outputs|outputs_addition\n",
    "\n",
    "print(len(outputs))\n",
    "\n",
    "vectorized_result = {}\n",
    "\n",
    "for file_name, descriptions in outputs.items():\n",
    "    text = descriptions[0]\n",
    "    inputs = tokenizer(text, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        output = model(**inputs)\n",
    "\n",
    "    embedding = output.pooler_output.squeeze().tolist()\n",
    "    vectorized_result[file_name] = embedding\n",
    "\n",
    "\n",
    "with open(OUTPUT_JSON, \"w\") as f:\n",
    "    json.dump(vectorized_result, f, indent=2)\n",
    "\n",
    "print(f\"Tokenized data saved to {OUTPUT_JSON}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd1302f",
   "metadata": {},
   "source": [
    "## VLM Distance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a749a74-962b-44e5-97a1-ca306bdc9e3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "\n",
    "# --- CONFIG ---\n",
    "VECTOR_JSON = \"outputs/combined_rgb/llava_test_vectorized.json\"\n",
    "\n",
    "# --- LOAD VECTOR DATA ---\n",
    "with open(VECTOR_JSON, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# --- GROUP VECTORS BY CLASS ---\n",
    "class_vectors = defaultdict(list)\n",
    "\n",
    "for file_name, vec in data.items():\n",
    "    match = re.search(r'_(\\d{2})\\.png$', file_name)\n",
    "    if match:\n",
    "        class_id = match.group(1)\n",
    "        class_vectors[class_id].append(np.array(vec, dtype=np.float32))\n",
    "\n",
    "# --- COMPUTE METRICS ---\n",
    "metrics = {}\n",
    "centroids = {}\n",
    "\n",
    "for class_id, vectors in class_vectors.items():\n",
    "    arr = np.stack(vectors)\n",
    "    norms = np.linalg.norm(arr, axis=1)\n",
    "\n",
    "    # Intra-class cosine similarity\n",
    "    if len(arr) > 1:\n",
    "        cos_sim_matrix = cosine_similarity(arr)\n",
    "        upper_tri_indices = np.triu_indices_from(cos_sim_matrix, k=1)\n",
    "        avg_cos_sim = np.mean(cos_sim_matrix[upper_tri_indices])\n",
    "    else:\n",
    "        avg_cos_sim = 1.0\n",
    "\n",
    "    centroid = arr.mean(axis=0)\n",
    "    centroids[class_id] = centroid\n",
    "\n",
    "    metrics[class_id] = {\n",
    "        \"num_samples\": len(arr),\n",
    "        \"avg_vector_norm\": float(np.mean(norms)),\n",
    "        \"max_vector_norm\": float(np.max(norms)),\n",
    "        \"min_vector_norm\": float(np.min(norms)),\n",
    "        \"intra_class_variance\": float(np.var(arr, axis=0).mean()),\n",
    "        \"avg_cosine_similarity\": float(avg_cos_sim)\n",
    "    }\n",
    "\n",
    "# --- INTER-CLASS VARIANCE CALCULATION ---\n",
    "# Convert centroids dict to ordered arrays\n",
    "class_ids = sorted(centroids.keys())\n",
    "centroid_matrix = np.stack([centroids[cid] for cid in class_ids])\n",
    "\n",
    "# Euclidean-based inter-class variance\n",
    "euclidean_dists = euclidean_distances(centroid_matrix)\n",
    "upper_tri_indices = np.triu_indices_from(euclidean_dists, k=1)\n",
    "avg_inter_class_variance = np.mean(euclidean_dists[upper_tri_indices])\n",
    "\n",
    "# Optional: cosine distance matrix for reference\n",
    "cosine_sim = cosine_similarity(centroid_matrix)\n",
    "cosine_dists = 1 - cosine_sim\n",
    "\n",
    "# --- REPORT ---\n",
    "print(\"\\nClass-wise Vector Metrics:\\n\")\n",
    "for class_id in class_ids:\n",
    "    stats = metrics[class_id]\n",
    "    print(f\"Class {class_id}:\")\n",
    "    for key, val in stats.items():\n",
    "        print(f\"  {key}: {val:.4f}\" if isinstance(val, float) else f\"  {key}: {val}\")\n",
    "    print()\n",
    "\n",
    "print(f\"\\nAverage Inter-Class Variance (Euclidean distance between centroids): {avg_inter_class_variance:.4f}\")\n",
    "\n",
    "# Optional: print cosine distance matrix\n",
    "print(\"\\nCosine Distance Matrix (1 - similarity):\")\n",
    "header = \"       \" + \" \".join([f\"{cid:>6}\" for cid in class_ids])\n",
    "print(header)\n",
    "for i, cid in enumerate(class_ids):\n",
    "    row = \"  \" + cid + \"  \" + \" \".join([f\"{cosine_dists[i, j]:6.3f}\" for j in range(len(class_ids))])\n",
    "    print(row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3283d9",
   "metadata": {},
   "source": [
    "## Read YOLO Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e10471-1bf3-4341-89bc-e5c795ff9d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from json_to_lists import read_yolo_json, get_labels\n",
    "\n",
    "yolo_names, yolo_data = read_yolo_json(\"./outputs/combined_rgb/yolo_test.json\")\n",
    "yolo_labels = get_labels(yolo_names)\n",
    "\n",
    "yolo_data_dict = dict(zip(yolo_names, yolo_data))\n",
    "yolo_label_dict = dict(zip(yolo_names, yolo_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3898d018",
   "metadata": {},
   "source": [
    "## Concatenate YOLO and VLM Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e059635",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_data = []\n",
    "concat_labels = []\n",
    "concat_names = []\n",
    "\n",
    "for name, embedding in vectorized_result.items():\n",
    "    concat_data.append(yolo_data_dict[name] + embedding)\n",
    "    concat_labels.append(yolo_label_dict[name])\n",
    "    concat_names.append(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd273757",
   "metadata": {},
   "source": [
    "## Create NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54fd112-cb36-45e6-aea3-ce41428d7b5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class class_nn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(class_nn, self).__init__()\n",
    "        self.fc1 = nn.Linear(888, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 12)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))  # Since output is bits (0â€“1)\n",
    "        return x\n",
    "\n",
    "model = class_nn()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263bd3b1",
   "metadata": {},
   "source": [
    "## Prepare training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713c9d86-2b76-408c-8a1e-a8e70d297e4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "\n",
    "inputs = torch.tensor(concat_data, dtype=torch.float32)\n",
    "targets = torch.tensor(concat_labels, dtype=torch.float32)\n",
    "\n",
    "dataset = TensorDataset(inputs, targets)\n",
    "\n",
    "split = 0.8\n",
    "train_size = int(len(inputs) * split)\n",
    "test_size = len(inputs) - train_size\n",
    "\n",
    "train_dataset = torch.utils.data.Subset(dataset, range(train_size))\n",
    "val_dataset = torch.utils.data.Subset(dataset, range(train_size, train_size + test_size))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "def count_label_combinations(dataset):\n",
    "    combo_counter = Counter()\n",
    "    for _, label in dataset:\n",
    "        key = tuple(label.int().tolist())  # convert tensor to tuple of ints\n",
    "        combo_counter[key] += 1\n",
    "    return combo_counter\n",
    "\n",
    "train_combos = count_label_combinations(train_dataset)\n",
    "val_combos = count_label_combinations(val_dataset)\n",
    "\n",
    "# Print results\n",
    "print(train_size)\n",
    "print(\"Train label combinations:\")\n",
    "for combo, count in train_combos.items():\n",
    "    print(f\"{combo}: {count}\")\n",
    "\n",
    "print(\"\\nValidation label combinations:\")\n",
    "for combo, count in val_combos.items():\n",
    "    print(f\"{combo}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c67c23",
   "metadata": {},
   "source": [
    "## Train NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4398c01-a373-48c4-a020-f4638718d683",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "criterion = nn.BCELoss()  # Binary Cross Entropy Loss for 12-bit outputs\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "epochs = 1000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for x_val, y_val in val_loader:\n",
    "            val_outputs = model(x_val)\n",
    "            val_loss += criterion(val_outputs, y_val).item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60bcde3",
   "metadata": {},
   "source": [
    "## Save trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a28dda-789d-41a1-9b25-c277d0643b57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "Path(\"classifier_weights\").mkdir(exist_ok=True)\n",
    "torch.save(model.state_dict(), 'classifier_weights/combined.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f61e5b6",
   "metadata": {},
   "source": [
    "## Load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8bb4a3-c9ce-4a0b-a757-6aa0bdc67317",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = class_nn()  # instantiate the model\n",
    "model.load_state_dict(torch.load('classifier_weights/combined.pth'))\n",
    "model.eval()  # set the model to evaluation mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089d7273",
   "metadata": {},
   "source": [
    "## Evaluate trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a95cec-cc62-48f8-89b4-32932075c2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = []\n",
    "all_labels = []\n",
    "def evaluate_accuracy(loader):\n",
    "    model.eval()\n",
    "    exact_matches = 0\n",
    "    total_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in loader:\n",
    "            outputs = model(x_batch)\n",
    "            predicted = (outputs > 0.5).float() # todo we can play with this maybe?\n",
    "            \n",
    "            # If error state last bit is 1 then all other should be 0\n",
    "            error_mask = predicted[:, -1] == 1  # samples where last bit is 1\n",
    "            predicted[error_mask, :-1] = 0      # set others to 0\n",
    "            \n",
    "            non_empty_mask = ~(y_batch.sum(axis=1) == 0)\n",
    "            predicted = predicted[non_empty_mask]\n",
    "            y_batch = y_batch[non_empty_mask]\n",
    "            \n",
    "            matches = (predicted == y_batch).all(dim=1)  # full match per sample\n",
    "           \n",
    "            exact_matches += matches.sum().item()\n",
    "            total_samples += y_batch.size(0)\n",
    "            \n",
    "            all_preds.extend([tuple(p.int().tolist()) for p in predicted])\n",
    "            all_labels.extend([tuple(y.int().tolist()) for y in y_batch])\n",
    "\n",
    "            \n",
    "    return exact_matches / total_samples\n",
    "\n",
    "train_acc = evaluate_accuracy(train_loader)\n",
    "val_acc = evaluate_accuracy(val_loader)\n",
    "\n",
    "print(f\"Train Accuracy: {train_acc:.2%}\")\n",
    "print(f\"Validation Accuracy: {val_acc:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0225cfe",
   "metadata": {},
   "source": [
    "## Generate confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e79937-0772-46e4-8580-fa97221bc5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def gen_confusion_matrix(all_preds, all_labels):\n",
    "    # Get all unique states across true and predicted\n",
    "    all_states = sorted(set(all_labels))\n",
    "    print(all_states)\n",
    "    state_to_index = {state: idx for idx, state in enumerate(all_states)}\n",
    "\n",
    "    # Convert state tuples to indices\n",
    "    y_true_idx = [state_to_index.get(state, len(all_states)) for state in all_labels]\n",
    "    y_pred_idx = [state_to_index.get(state, len(all_states)) for state in all_preds]\n",
    "    \n",
    "    cm = confusion_matrix(y_true_idx, y_pred_idx)\n",
    "    return cm, all_states\n",
    "\n",
    "\n",
    "def plot_state_confusion_matrix(cm, state_labels, title=\"Confusion Matrix of States- YOLO\", save_path=None, normalize=True):\n",
    "    # Convert tuples like (1, 0, 1) to strings: \"101\"\n",
    "    state_strs = [''.join(map(str, state)) for state in state_labels]\n",
    "    state_strs.append(\"other\")\n",
    "\n",
    "    if normalize:\n",
    "        # Normalize rows to sum to 1 (avoid division by zero)\n",
    "        cm_normalized = cm.astype('float')\n",
    "        row_sums = cm_normalized.sum(axis=1, keepdims=True)\n",
    "        cm_normalized = cm_normalized / row_sums\n",
    "        cm_normalized = pd.DataFrame(cm_normalized, index=state_strs, columns=state_strs)\n",
    "        fmt = \".2f\"\n",
    "        data_to_plot = cm_normalized\n",
    "    else:\n",
    "        # Use raw counts\n",
    "        data_to_plot = pd.DataFrame(cm, index=state_strs, columns=state_strs)\n",
    "        fmt = \"d\"\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(data_to_plot, annot=True, fmt=fmt, cmap=\"Reds\", cbar=True)\n",
    "    plt.title(title)\n",
    "    plt.ylabel(\"True State\")\n",
    "    plt.xlabel(\"Predicted State\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "cm, all_states = gen_confusion_matrix(all_preds, all_labels)\n",
    "plot_state_confusion_matrix(cm, all_states, save_path=\"Confusion_matrix_Yolo\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
