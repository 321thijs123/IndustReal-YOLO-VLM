{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae4b1a6b",
   "metadata": {},
   "source": [
    "# Classifier - Using YOLO outputs only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19c12ab",
   "metadata": {},
   "source": [
    "## Read YOLO outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e10471-1bf3-4341-89bc-e5c795ff9d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from json_to_lists import read_yolo_json, get_labels\n",
    "\n",
    "names, datas = read_yolo_json(\"./outputs/combined_rgb/yolo_test.json\")\n",
    "labels = get_labels(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b861239",
   "metadata": {},
   "source": [
    "## Create NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54fd112-cb36-45e6-aea3-ce41428d7b5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class class_nn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(class_nn, self).__init__()\n",
    "        self.fc1 = nn.Linear(120, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 12)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))  # Since output is bits (0â€“1)\n",
    "        return x\n",
    "\n",
    "model = class_nn()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f141ff17",
   "metadata": {},
   "source": [
    "## Prepare training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713c9d86-2b76-408c-8a1e-a8e70d297e4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "\n",
    "inputs = torch.tensor(datas, dtype=torch.float32)\n",
    "targets = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "dataset = TensorDataset(inputs, targets)\n",
    "\n",
    "split = 0.8\n",
    "train_size = int(len(inputs) * split)\n",
    "test_size = len(inputs) - train_size\n",
    "\n",
    "train_dataset = torch.utils.data.Subset(dataset, range(train_size))\n",
    "val_dataset = torch.utils.data.Subset(dataset, range(train_size, train_size + test_size))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "def count_label_combinations(dataset):\n",
    "    combo_counter = Counter()\n",
    "    for _, label in dataset:\n",
    "        key = tuple(label.int().tolist())  # convert tensor to tuple of ints\n",
    "        combo_counter[key] += 1\n",
    "    return combo_counter\n",
    "\n",
    "train_combos = count_label_combinations(train_dataset)\n",
    "val_combos = count_label_combinations(val_dataset)\n",
    "\n",
    "# Print results\n",
    "print(train_size)\n",
    "print(\"Train label combinations:\")\n",
    "for combo, count in train_combos.items():\n",
    "    print(f\"{combo}: {count}\")\n",
    "\n",
    "print(\"\\nValidation label combinations:\")\n",
    "for combo, count in val_combos.items():\n",
    "    print(f\"{combo}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70eba9ca",
   "metadata": {},
   "source": [
    "## Train NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4398c01-a373-48c4-a020-f4638718d683",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "criterion = nn.BCELoss()  # Binary Cross Entropy Loss for 12-bit outputs\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for x_val, y_val in val_loader:\n",
    "            val_outputs = model(x_val)\n",
    "            val_loss += criterion(val_outputs, y_val).item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd01173c",
   "metadata": {},
   "source": [
    "## Save trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a28dda-789d-41a1-9b25-c277d0643b57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "Path(\"classifier_weights\").mkdir(exist_ok=True)\n",
    "torch.save(model.state_dict(), 'classifier_weights/yolo_only.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09666d65",
   "metadata": {},
   "source": [
    "## Load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8bb4a3-c9ce-4a0b-a757-6aa0bdc67317",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = class_nn()  # instantiate the model\n",
    "model.load_state_dict(torch.load('classifier_weights/yolo_only.pth'))\n",
    "model.eval()  # set the model to evaluation mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b50f7c4",
   "metadata": {},
   "source": [
    "## Evaluate trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a95cec-cc62-48f8-89b4-32932075c2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = []\n",
    "all_labels = []\n",
    "def evaluate_accuracy(loader):\n",
    "    model.eval()\n",
    "    exact_matches = 0\n",
    "    total_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in loader:\n",
    "            outputs = model(x_batch)\n",
    "            predicted = (outputs > 0.5).float() # todo we can play with this maybe?\n",
    "            \n",
    "            # If error state last bit is 1 then all other should be 0\n",
    "            error_mask = predicted[:, -1] == 1  # samples where last bit is 1\n",
    "            predicted[error_mask, :-1] = 0      # set others to 0\n",
    "            \n",
    "            non_empty_mask = ~(y_batch.sum(axis=1) == 0)\n",
    "            predicted = predicted[non_empty_mask]\n",
    "            y_batch = y_batch[non_empty_mask]\n",
    "            \n",
    "            matches = (predicted == y_batch).all(dim=1)  # full match per sample\n",
    "           \n",
    "            exact_matches += matches.sum().item()\n",
    "            total_samples += y_batch.size(0)\n",
    "            \n",
    "            all_preds.extend([tuple(p.int().tolist()) for p in predicted])\n",
    "            all_labels.extend([tuple(y.int().tolist()) for y in y_batch])\n",
    "\n",
    "            \n",
    "    return exact_matches / total_samples\n",
    "\n",
    "train_acc = evaluate_accuracy(train_loader)\n",
    "val_acc = evaluate_accuracy(val_loader)\n",
    "\n",
    "print(f\"Train Accuracy: {train_acc:.2%}\")\n",
    "print(f\"Validation Accuracy: {val_acc:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7a8292",
   "metadata": {},
   "source": [
    "## Generate confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e79937-0772-46e4-8580-fa97221bc5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def gen_confusion_matrix(all_preds, all_labels):\n",
    "    # Get all unique states across true and predicted\n",
    "    all_states = sorted(set(all_labels))\n",
    "    print(all_states)\n",
    "    state_to_index = {state: idx for idx, state in enumerate(all_states)}\n",
    "\n",
    "    # Convert state tuples to indices\n",
    "    y_true_idx = [state_to_index.get(state, len(all_states)) for state in all_labels]\n",
    "    y_pred_idx = [state_to_index.get(state, len(all_states)) for state in all_preds]\n",
    "    \n",
    "    cm = confusion_matrix(y_true_idx, y_pred_idx)\n",
    "    return cm, all_states\n",
    "\n",
    "\n",
    "def plot_state_confusion_matrix(cm, state_labels, title=\"Confusion Matrix of States- YOLO\", save_path=None, normalize=True):\n",
    "    # Convert tuples like (1, 0, 1) to strings: \"101\"\n",
    "    state_strs = [''.join(map(str, state)) for state in state_labels]\n",
    "    state_strs.append(\"other\")\n",
    "\n",
    "    if normalize:\n",
    "        # Normalize rows to sum to 1 (avoid division by zero)\n",
    "        cm_normalized = cm.astype('float')\n",
    "        row_sums = cm_normalized.sum(axis=1, keepdims=True)\n",
    "        cm_normalized = cm_normalized / row_sums\n",
    "        cm_normalized = pd.DataFrame(cm_normalized, index=state_strs, columns=state_strs)\n",
    "        fmt = \".2f\"\n",
    "        data_to_plot = cm_normalized\n",
    "    else:\n",
    "        # Use raw counts\n",
    "        data_to_plot = pd.DataFrame(cm, index=state_strs, columns=state_strs)\n",
    "        fmt = \"d\"\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(data_to_plot, annot=True, fmt=fmt, cmap=\"Reds\", cbar=True)\n",
    "    plt.title(title)\n",
    "    plt.ylabel(\"True State\")\n",
    "    plt.xlabel(\"Predicted State\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "cm, all_states = gen_confusion_matrix(all_preds, all_labels)\n",
    "plot_state_confusion_matrix(cm, all_states, save_path=\"Confusion_matrix_Yolo\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
